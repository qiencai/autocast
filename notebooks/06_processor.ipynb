{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## AutoCast processor training example\n",
    "\n",
    "This notebook demonstrates training a processor directly on encoded data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Example dataaset\n",
    "\n",
    "We use the `ReactionDiffusion` dataset as an example dataset to illustrate training and evaluation of models. This dataset simulates the advection-diffusion equation in 2D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocast.data.encoded_dataset import MiniWellDataModule\n",
    "from autocast.metrics.spatiotemporal import MAE, MSE, RMSE, VRMSE\n",
    "\n",
    "THE_WELL = False\n",
    "simulation_name = \"rayleigh_benard\"\n",
    "n_steps_input = 1\n",
    "n_steps_output = 4\n",
    "stride = 1\n",
    "rollout_stride = 4\n",
    "\n",
    "\n",
    "base_path = (\n",
    "    f\"../datasets/{simulation_name}/1e3z5x2c_{simulation_name}_dcae_f32c64_large/cache/{simulation_name}\"\n",
    ")\n",
    "datamodule = MiniWellDataModule(\n",
    "    data_path=base_path,\n",
    "    n_steps_input=n_steps_input, n_steps_output=n_steps_output, stride=stride\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Set-up logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocast.logging import maybe_watch_model\n",
    "from autocast.logging.wandb import create_notebook_logger\n",
    "\n",
    "logger, watch = create_notebook_logger(\n",
    "    project=\"autocast-notebooks\",\n",
    "    name=f\"06_processor_{simulation_name}\",\n",
    "    tags=[\"notebook\", simulation_name],\n",
    "    enabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(datamodule.train_dataloader()))\n",
    "n_channels = batch.encoded_inputs.shape[-1]\n",
    "w, h = batch.encoded_inputs.shape[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Example shape and batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_dataset[0].encoded_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(datamodule.train_dataloader()))\n",
    "\n",
    "batch.encoded_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azula.noise import VPSchedule\n",
    "\n",
    "from autocast.models.processor import ProcessorModel\n",
    "from autocast.nn.unet import TemporalUNetBackbone\n",
    "from autocast.processors.flow_matching import FlowMatchingProcessor\n",
    "\n",
    "batch = next(iter(datamodule.train_dataloader()))\n",
    "n_channels = batch.encoded_inputs.shape[-1]\n",
    "\n",
    "# processor_name = \"flow_matching\"  # set to \"diffusion\" to compare\n",
    "processor_name = \"diffusion\"  # set to \"flow_matching\" to compare\n",
    "n_latent_in = batch.encoded_inputs.shape[-1]\n",
    "n_latent_out = batch.encoded_output_fields.shape[-1]\n",
    "backbone = TemporalUNetBackbone(\n",
    "    in_channels=n_latent_out,\n",
    "    out_channels=n_latent_out,\n",
    "    cond_channels=n_latent_in,\n",
    "    n_steps_output=n_steps_output,\n",
    "    n_steps_input=n_steps_input,\n",
    "    mod_features=200,\n",
    "    hid_channels=(32, 64, 128),\n",
    "    hid_blocks=(2, 2, 2),\n",
    "    spatial=2,\n",
    "    periodic=False,\n",
    ")\n",
    "\n",
    "if processor_name == \"flow_matching\":\n",
    "    processor = FlowMatchingProcessor(\n",
    "        backbone=backbone,\n",
    "        schedule=VPSchedule(),  # accepted for API parity, not used internally\n",
    "        n_steps_output=n_steps_output,\n",
    "        n_channels_out=n_latent_out,\n",
    "        stride=stride,\n",
    "        flow_ode_steps=4,\n",
    "    )\n",
    "else:\n",
    "    from autocast.processors.diffusion import DiffusionProcessor\n",
    "\n",
    "    processor = DiffusionProcessor(\n",
    "        backbone=backbone,\n",
    "        schedule=VPSchedule(),\n",
    "        n_steps_output=n_steps_output,\n",
    "        n_channels_out=n_latent_out,\n",
    "    )\n",
    "\n",
    "model = ProcessorModel(\n",
    "    processor=processor,\n",
    "    learning_rate=5e-4,\n",
    "    test_metrics=[VRMSE(), MSE(), MAE(), RMSE()],\n",
    ")\n",
    "maybe_watch_model(logger, model, watch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batch.encoded_inputs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Run trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "# device = \"mps\"  # \"cpu\"\n",
    "device = \"cuda\"  # \"cpu\"\n",
    "trainer = L.Trainer(max_epochs=2, accelerator=device, logger=logger)\n",
    "trainer.fit(model, datamodule)\n",
    "trainer.save_checkpoint(f\"./{simulation_name}_{processor_name}_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Run the evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
