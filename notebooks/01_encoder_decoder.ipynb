{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from hydra import compose, initialize_config_dir\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "CONFIG_DIR = (Path.cwd() / \"../configs\").resolve()\n",
    "\n",
    "# Example overrides for quick testing:\n",
    "overrides = [\n",
    "    # \"trainer.max_epochs=1\",\n",
    "    # \"trainer.accelerator=cpu\",\n",
    "    # \"data.split.n_train=2\",\n",
    "    # \"data.split.n_valid=1\",\n",
    "    # \"data.split.n_test=1\",\n",
    "]\n",
    "\n",
    "with initialize_config_dir(version_base=None, config_dir=str(CONFIG_DIR)):\n",
    "    cfg = compose(config_name=\"autoencoder\", overrides=overrides)\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocast.logging import create_wandb_logger, maybe_watch_model\n",
    "\n",
    "cfg.logging.wandb.enabled = True\n",
    "cfg.logging.wandb.project = \"autocast-notebooks\"\n",
    "cfg.logging.wandb.name = \"01_encoder_decoder\"\n",
    "resolved_cfg = OmegaConf.to_container(cfg, resolve=True)\n",
    "wandb_logger, wandb_watch = create_wandb_logger(\n",
    "    cfg.logging,\n",
    "    experiment_name=\"01_encoder_decoder\",\n",
    "    job_type=\"notebook\",\n",
    "    config={\"hydra\": resolved_cfg} if resolved_cfg is not None else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocast.train.autoencoder import build_datamodule\n",
    "\n",
    "datamodule = build_datamodule(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autocast.types.batch import Batch\n",
    "\n",
    "batch: Batch = next(iter(datamodule.train_dataloader()))\n",
    "train_inputs = batch.input_fields\n",
    "train_outputs = batch.output_fields\n",
    "train_inputs.shape, train_outputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.allclose(train_inputs, train_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_count = train_inputs.shape[-1]\n",
    "cfg.model.encoder.in_channels = channel_count\n",
    "cfg.model.decoder.out_channels = channel_count\n",
    "print(f\"Detected {channel_count} channels; config updated to match input distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.utils import instantiate\n",
    "\n",
    "from autocast.train.autoencoder import build_model\n",
    "\n",
    "model = build_model(cfg.model)\n",
    "maybe_watch_model(wandb_logger, model, wandb_watch)\n",
    "trainer = instantiate(\n",
    "    cfg.trainer,\n",
    "    logger=wandb_logger,\n",
    "    enable_checkpointing=False,\n",
    "    default_root_dir=\".\",\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=datamodule.train_dataloader(),\n",
    "    val_dataloaders=datamodule.val_dataloader(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "checkpoint_path = Path(\"notebook_autoencoder.ckpt\")\n",
    "trainer.save_checkpoint(checkpoint_path)\n",
    "checkpoint_path.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cpu\"\n",
    "num_examples = 2\n",
    "\n",
    "for idx, batch in enumerate(datamodule.test_dataloader()):\n",
    "    inputs = batch.input_fields.to(device)\n",
    "    outputs, latents = model.forward_with_latent(batch)\n",
    "    print(\"Input shape:\", inputs.shape)\n",
    "    print(\"Output shape:\", outputs.shape)\n",
    "    print(\"Latent shape:\", latents.shape)\n",
    "\n",
    "    input_frame = inputs[0, 0, :, :, 0].detach().cpu().numpy()\n",
    "    output_frame = outputs[0, 0, :, :, 0].detach().cpu().numpy()\n",
    "    latent_frame = latents[0, 0, :, :, 0].detach().cpu().numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 4))\n",
    "    axs[0].imshow(input_frame, cmap=\"viridis\")\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].imshow(output_frame, cmap=\"viridis\")\n",
    "    axs[1].set_title(\"Reconstruction\")\n",
    "    axs[2].imshow(output_frame - input_frame, cmap=\"viridis\")\n",
    "    axs[2].set_title(\"Difference\")\n",
    "    axs[3].imshow(latent_frame, cmap=\"viridis\")\n",
    "    axs[3].set_title(\"Latent\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if idx + 1 >= num_examples:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
